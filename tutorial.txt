Take-away topics:
* Test your code.
  Why: * If other people rely on your code or the results from your code,
         it needs to be tested ("I don't have time to write tests" is not
         really a valid excuse, IMO.)
       * Even for well-designed, loosely coupled code, new development has
         the potential for breaking existing functionality.  A good set
         of tests can guard against that.
  How: There are all sorts of ways to test code: integration, functional,
       regression.  I will talk about unit tests because these bear most
       directly on how does development on a day-to-day, minute-to-minute
       basis.
       * Unit tests apply to the lowest level components:
         classes and functions.
       * Run the unit tests often through the development cycle.
       * Output of successful tests should be minimal.  If you have to
         look at the output to verify success, you will run them less
         often.
       * Make them automated and easy to run.
       * Use a standard testing framework (e.g., unittest) and hook it
         up to a continuous build system (Travis CI, Jenkins).
       * Consider Test first development, TDD.

* Have other people look at your code, look at other people's code.
  Why: * Coding is a craft and over time standard practices and tools
         have evolved that help make the code more reliable (e.g.,
         design patterns).
         It can be taught, but most people, especially scientists, learn
         it on their own.  Learn from and teach others.
         Finally, for a group software project, there is a lot of risk
         if there is only one person who understands or can maintain
         an important part of the codebase.
  How: * Pair program.
       * Do code review.
       * Share your code on GitHub.
       * Use a weak code-ownership model, i.e., encourage people to
         work all parts of the code.

* Have a set of coding conventions for your group.  Follow the
  established conventions of groups you join.

  Why: Coding conventions/style is like a dialect: two developers
       may be using the same language (e.g., Python, C++), but if
       their coding styles differ substantially, they'll have
       trouble understanding each others code.
  How: * Adopt standard conventions, e.g., PEP8, but more importantly,
         reach consensus on the conventions you do adopt.
       * Use code checking tools, like PyLint.  These also perform
         static code analysis to check for potential bugs.
       * Use editor plugins for the code checking tools.
       (Aside: having code pass linter tests means that the code
       reviewer can concentrate on substantive features of the
       implementation, thereby making the review more valuable.)

Demos:
* github flow  (slides with screenshots)
  * work on branches, master is never broken
* bug-fixing Primes using testing framework and editor plugins (live).
  * run nosetests from command line to show that tests fail.
  * Run fixes in emacs:  $ emacs tests/test_Primes.py
    * Show nosetests execution to replicate failure
    * Show pylint execution to show stats.
    * Add a test function (without a docstring) to demo jedi autocompletion.
    * Go to top of file and run pylint again to demo C-x` 'next-error
    * Fix docstring, run pylint
    * Run nosetests
    * Edit production code.
    * Run nosetests from python/desc/primes/Primes.py

* using Travis CI:
  <be sure Primes is broken and travi-ci is set to trigger on push>
  * Go to Primes repo
    -> Settings tab
    -> Webhooks & services
    -> Show Add service pull-down
  * Go to travis-ci.org
     -> '+' next to My Repositories
     -> click Sync account button
     -> toggle switch to turn on service for that repo
     -> click settings symbol to toggle build on push or PR
  * Go back to Primes
    -> Show the .travis.yml configuration.
    -> Edit Travis CI button.
    -> Click Test Service to trigger a build.
    <wait for failure>
  * Go to code
    -> edit production code to trigger build
    <wait for success>

-------------------------------------------------------------------------

Potential topics to cover from CI2
* continuous integration systems
* package management system (eups)
* external libraries
* DESC developer framework
* build tools (SCons)
* Coding practice goals:
  * dev environment needs to achieve desired levels of scientific
    accuracy and reproducibility.
  * writing code that is also maintainable and extensible
  * DESC practices should be arrived at by consensus (not everyone will
    be completely happy, but we will have a common understanding).

The strawman proposal:
* All code goes into DESC GitHub repositories.  This enables sharing of
  code throughout the collaboration, enhancing communication and reducing
  frictions in working together.

* Repos should be organized in a standard way.  This makes it easier
  for a package to be navigated and understood by an outside
  developer, e.g., for C++ code the .h files are in a standard
  location (also leading to a standard syntax for #include
  statements).  Template packages will be provided to help DESC
  developers make new repos with the common structure.

* Coding style guidelines will be developed and their use encouraged.
  These will be made easier to follow with linters, etc..  For
  infrastructure and production ("core") code, these guidelines will
  be enforced.  Having a uniform coding style makes the code easier to
  understand and allows code reviewer to concentrate on algorithmic or
  design issues instead of syntatic elements.

* Regular code reviews should occur to ensure code quality and to make
  sure development in a given package proceeds in a useful direction.
  This will be essential for core code, but it would also be useful
  for non-core code, especially if that code eventually gets used for
  a DESC publication or is integrated into the production system.  The
  precise scope and nature of the code reviews is TBD, but the goals
  should be to have reliable, efficient, maintainable, and
  well-documented code.

* A standard workflow such as GitHub-flow enables multiple developers to
  work on the same package while minimizing conflicts that can arise
  from concurrent development.  A standard workflow also give clear guidance
  to new developers on how to contribute.

* Systematic and regular testing procedures are a key means of
  maintaining software reliability and quality.  Testing can occur at
  several levels, e.g., system testing, integration testing, and unit
  testing.  Unit tests are implemented to ensure that the code at the
  function and class level behaves as expected.  Having a
  comprehensive set of tests can significantly reduce development
  time, as they can allow for aggressive refactoring, and continuous
  testing helps minimize the introduction of bugs while working on new
  features.

  Unit tests are implemented using "testing frameworks" such as
  unittest and can be triggered to run automatically in CI tools such
  as Jenkins and travis-ci.

* Introduction
  * Discuss CI2 study group and report.
  * Make case for common development practices.
  * Discuss differing levels of applicability: core code vs non-core.
  * DM team policies as the default strawman.

* Topics
  * GitHub
  * Package/repository organization
  * Coding style guides
  * Code review
  * Development workflows
  * Automated testing

* Coding conventions and style guidelines.
  * DM team choices: PEP8-ish for Python, C++.
  * DESC's should be similarly informed by its developers.
  * Benefits:
    * Common idioms make code easier to understand.
    * Syntatic consistency makes it easier to spot bugs.
    * Code review is enabled.
    * New developers have definitive guidance on how to contribute.
    * Adopting a software group's established coding style is a
      social norm.

* Development Tools
  * Linters and code checking tools (pylint, Clang, etc.. )
    * Check adherence to style conventions: indentations, naming
      conventions, line length, comment formatting, etc..
    * Static analysis to spot interface inconsistencies (e.g., usage),
      duplicated code, unused code, use of deprecated features, class
      structure.
    * Can be run standalone, but more useful as plugins to editors
      (emacs, vim, sublime) and IDEs.  Can also be run as part of CI,
      with metrics tracked.
  * IDEs (pyCharm, ...)
    * enable refactoring, using the build system, debugging; provides
      hooks to version control system.
  * cookiecutter templates for creating new software projects
  * CI tools: Jenkins, travis-ci
  * Issue tracking systems: JIRA, Zenhub, GitHub issues

* Development Workflows
  * A way for several developers to contribute to a repo and avoid
    collisions/inconsistency in concurrent development.  (Testing is
    also an integral part of this.)
  * Strict adherence to a development workflow may not make sense if there
    is only one developer or if the package is at an early stage.
  * DM team's workflow is based on GitHub flow, and uses JIRA to assign
    and track the progress on issues.
  * GitHub flow for DESC use: (https://guides.github.com/introduction/flow/)
    * Create a branch off of master
    * commit code (following TDD practices: write tests defining the scope
      of the development, modify production code to satisify new and
      existing tests, refactor, test again).
    * Open a pull request:  This can be done at any time (even before
      creating the branch).  The PR is the forum for discussing
      the development, including scope, design issues, implementation
      issues, and ultimately ends in a code review.
    * Trigger a CI build of the branch. Fix any problems.
    * Merge changes to master.  This would also trigger a CI build.

* Testing
  * Types of tests: system, functional, regression, unit
  * Unit test benefits:
    * Ensures, at least at the interface level, that the code works.
    * Reveals certain kinds of bugs immediately.
    * Enables developers to refactor aggressively, leading to more
      maintainable and reliable code.
  * What to test:
    * DM team identifies three different areas: 
      (http://developer.lsst.io/en/latest/coding/unit_test_policy.html)
      * White-box tests: using standard input datasets to test the
        internal logic of a module.
      * Black-box tests: tests designed based on the expected outputs
        of a module given a set of standard inputs that exercise
        the full range of behavior.
      * Performance tests: used if the design has resource constraints
        that it must satisfy.
  * How to write tests (http://www.diveintopython.net/unit_testing/index.html)
    * Test for success, failure, sanity. <give examples>
    * Unit tests should run fast enough so that they can be run at
      will in at the finest level of granularity.
  * Testing frameworks
    * Generically, xUnit, and unittest for Python.
    * Show running of unittest (as a blackbox) at the command line.
    * Discuss philosophy of having minimal output of passed tests
  * Test Driven Development
    (http://butunclebob.com/ArticleS.UncleBob.TheThreeRulesOfTdd)
    * The three rules of TDD:
      1. No mods to production code unless it is to make a failing test
         pass.
      2. Unit tests should be minimally written, i.e., no more than is
         required to test the relevant feature.
      3. Additions to production code should be limited to no more than
         is required to pass the one failing test.  This is to avoid the
         addition of untested code.
    * We'll do an exercise on this in the tutorial.

Live Demos/tutorials:
* TDD exercise.
  * (refer to the advertised fizzbuzz coding exercise)
  * Recap rules of the fizzbuzz game.
  * Write first test:
    * Illustrate jedi command completion.
    * Run pylint and PEP8 in emacs.
    * Run tests.
  * Iterate:
    * Write implementation to fix test
    * Run tests
    * Refactor
    * Add next test
    * Run tests showing failure

* GitHub flow example:
  * Go to repo and look at Phil's bug issue
  * Clone repo
  * Create issue branch
  * implement test
  * run tests showing failure
  * implement fix
  * run tests
  * commit changes, push to branch, issue PR
  * Phil reviews changes, merges to master, triggering travis-ci build
  * Go to next issue
